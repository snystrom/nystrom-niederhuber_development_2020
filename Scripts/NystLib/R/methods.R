# XXX:
# TODO:
#  Port to work with peakExperimentSet object, append another column with <annotation_basename>_<summitStart>
#  where this column contains the summit STARTSITE ?
# End.
compare_behavior_between_contrasts <- function(reference, test, feature_metadata, 
                                               annotation_basename, 
                                               idcol = "id"){
	    # Where reference & test are dataframes generated by generate_DESeq2_contrasts 
	    # Purpose is to compare for example, differences in behavior between two conditions.
	    # for example, peaks that increase in wild-type are annotated in WT-Time1vsWT-Time2, 
	    # while peaks that are affected by mutating a gene are annotated in mut-Time1vsmut-Time2.
	    # By comparing the differences in behavior between these two conditions, we can determine which 
	    # regions are affected by the mutation, ergo that gene is required for the wild-type changes to occurr.
	    #
	    # Usage: `reference` is the "wild-type", `test` is the "mutant" in the above example.
	    #
	    # features are annotated as <affected | unaffected>_<behavior_in_results1>
        # Two columns are added to the feature_metadata file, annotation_basename_full & annotation_basename_simple
        # simple is annnoatted as "(un)affected_<behavior_in_reference>"
        # full is annnoatted as "(un)affected_<behavior_in_reference>.<behavior_in_test>"
        # The idea here is to allow grouping by many parameters (complex & simple) 
        # and to abstract as many of those manipulations away from the user as possible for ease of use and code readability.
    
        # feature_metadata is at minimum a dataframe with a single 'id' column (matching the features used in DESeq)
        #       can be easily generated by feature_metadata <- data.frame("id" = rownames(dds))
        # annotation_basename is the base string for the output columns (<base>_full, <base>_simple)
        # reference & test are two DEseq2 contrasts. 
            # WARNING: Ensure their direcionality makes sense so that the behaviors are comparable!
            # (ie ensure that for both contrasts "increasing" means the same thing in each individual dataset, 
            # otherwise output will be exactly opposite of expected)
    
    ########
	# Checks:
    ########
  
    feature_metadata <- switch(class(feature_metadata),
                               GRanges = mcols(feature_metadata) %>% data.frame,
                               data.frame = feature_metadata)
    
    if (!("id" %in% names(feature_metadata))) {
        # TODO:
        # Allow nonstandard evaluation of 'id' column.
        # End.
        stop("ERROR: feature_metadata does not have an 'id' column.")
    }
  
    test <- switch(class(test),
           GRanges = mcols(test) %>% data.frame,
           data.frame = test)
    
    reference <- switch(class(reference),
           GRanges = mcols(reference) %>% data.frame,
           data.frame = reference)
    
    # Parse colnames:
    bool_annotation_colname <- paste0(annotation_basename, "_bool")
    simple_annotation_colname <- paste0(annotation_basename, "_simple")
    full_annotation_colname <- paste0(annotation_basename, "_full")
    
    # Grab data
    # Replace NA with "NA" (string) so that NA values will be correctly compared
    ref_output <- reference %>% 
        dplyr::select(id, behavior_type) %>% 
        tidyr::replace_na(., replace = list(behavior_type = "NA"))

    # XXX:            
    # need a way to figure out how to handle this line if using NSE to get the idcol
    names(ref_output) <- paste0("reference_", names(ref_output))
    ref_output <- rename(ref_output, reference_id = "id")
    # End.
    
    test_output <- test %>% 
        dplyr::select(id, behavior_type) %>% 
        tidyr::replace_na(., replace = list(behavior_type = "NA"))
    names(test_output) <- paste0("test_", names(test_output))
    test_output <- rename(test_output, test_id = "id")
    
    # merge comparison data with feature information:
    behavior_comparison <- dplyr::select(feature_metadata, id)
    behavior_comparison <- behavior_comparison %>%
          dplyr::left_join(., ref_output, by = "id") %>% 
          dplyr::left_join(., test_output, by = "id")
    
    # First assign simple & full behavior descriptors: 
    behavior_comparison[[simple_annotation_colname]] <- behavior_comparison$reference_behavior_type
    
    behavior_comparison[[full_annotation_colname]] <- paste0(behavior_comparison$reference_behavior_type,
                                                             ".", behavior_comparison$test_behavior_type)
    
    # Decide which features are affected & unaffected (store in $effect_str) 
    behavior_comparison[[bool_annotation_colname]] <- (behavior_comparison$reference_behavior_type != behavior_comparison$test_behavior_type)
    
    behavior_comparison <- behavior_comparison %>% 
                           mutate(effect_str = case_when(
                               .[[bool_annotation_colname]] == FALSE ~ "unaffected_",
                               .[[bool_annotation_colname]] == TRUE ~ "affected_")) 
    
    # Add affected/unaffected strings to simple & full behavior descriptors
    behavior_comparison[[simple_annotation_colname]] <- paste0(behavior_comparison$effect_str,
                                                               behavior_comparison[[simple_annotation_colname]])
    behavior_comparison[[full_annotation_colname]] <- paste0(behavior_comparison$effect_str,
                                                             behavior_comparison[[full_annotation_colname]])
    
    # Drop the extraneous columns used in processing, remerge with feature_metadata & return
    comparison_data <- behavior_comparison %>% select_("id",
                                                       simple_annotation_colname, 
                                                       full_annotation_colname,
                                                       bool_annotation_colname)
    feature_metadata <- dplyr::left_join(feature_metadata, comparison_data, by = "id")
    
    return(feature_metadata)
}


compare_column_between_contrasts <- function(reference, test, colName_ref, colName_test, feature_metadata, 
                                               annotation_basename, 
                                               idcol = "id"){
        # Inputs are specific columns of reference & test, function will append affected_ 
        # etc and return dataframe
    
           # Adapted from compare_behavior_between_contrasts:
    
	    # Where reference & test are dataframes generated by generate_DESeq2_contrasts 
	    # Purpose is to compare for example, differences in behavior between two conditions.
	    # for example, peaks that increase in wild-type are annotated in WT-Time1vsWT-Time2, 
	    # while peaks that are affected by mutating a gene are annotated in mut-Time1vsmut-Time2.
	    # By comparing the differences in behavior between these two conditions, we can determine which 
	    # regions are affected by the mutation, ergo that gene is required for the wild-type changes to occurr.
	    #
	    # Usage: `reference` is the "wild-type", `test` is the "mutant" in the above example.
	    #
	    # features are annotated as <affected | unaffected>_<behavior_in_results1>
        # Two columns are added to the feature_metadata file, annotation_basename_full & annotation_basename_simple
        # simple is annnoatted as "(un)affected_<behavior_in_reference>"
        # full is annnoatted as "(un)affected_<behavior_in_reference>.<behavior_in_test>"
        # The idea here is to allow grouping by many parameters (complex & simple) 
        # and to abstract as many of those manipulations away from the user as possible for ease of use and code readability.
    
        # feature_metadata is at minimum a dataframe with a single 'id' column (matching the features used in DESeq)
        #       can be easily generated by feature_metadata <- data.frame("id" = rownames(dds))
        # annotation_basename is the base string for the output columns (<base>_full, <base>_simple)
        # reference & test are two DEseq2 contrasts. 
            # WARNING: Ensure their direcionality makes sense so that the behaviors are comparable!
            # (ie ensure that for both contrasts "increasing" means the same thing in each individual dataset, 
            # otherwise output will be exactly opposite of expected)
    
    ########
	# Checks:
    ########
  
    feature_metadata <- switch(class(feature_metadata),
                               GRanges = mcols(feature_metadata) %>% data.frame,
                               data.frame = feature_metadata,
                               DataFrame = feature_metadata %>% data.frame)
    
    if (!("id" %in% names(feature_metadata))) {
        # TODO:
        # Allow nonstandard evaluation of 'id' column.
        # End.
        stop("ERROR: feature_metadata does not have an 'id' column.")
    }
  
    test <- switch(class(test),
           GRanges = mcols(test) %>% data.frame,
           data.frame = test,
           DataFrame = test %>% data.frame)
    
    reference <- switch(class(reference),
           GRanges = mcols(reference) %>% data.frame,
           data.frame = reference, 
           DataFrame = reference %>% data.frame)
    
    # Parse colnames:
    bool_annotation_colname <- paste0(annotation_basename, "_bool")
    simple_annotation_colname <- paste0(annotation_basename, "_simple")
    full_annotation_colname <- paste0(annotation_basename, "_full")
    
    # Grab data
    # Replace NA with "NA" (string) so that NA values will be correctly compared
    ref_output <- reference %>% 
        dplyr::select(id, colName_ref) 

    # XXX:            
    # need a way to figure out how to handle this line if using NSE to get the idcol
    names(ref_output) <- paste0("reference_", names(ref_output))
    ref_output <- rename(ref_output, reference_id = "id")
    # End.
    
    test_output <- test %>% 
        dplyr::select(id, colName_test)
    names(test_output) <- paste0("test_", names(test_output))
    test_output <- rename(test_output, test_id = "id")
    
    # merge comparison data with feature information:
    behavior_comparison <- dplyr::select(feature_metadata, id)
    behavior_comparison <- behavior_comparison %>%
          dplyr::left_join(., ref_output, by = "id") %>% 
          dplyr::left_join(., test_output, by = "id")
    
    # First assign simple & full behavior descriptors: 
    behavior_comparison[[simple_annotation_colname]] <- behavior_comparison$reference_behavior_type
    
    behavior_comparison[[full_annotation_colname]] <- paste0(behavior_comparison$reference_behavior_type,
                                                             ".", behavior_comparison$test_behavior_type)
    
    # Decide which features are affected & unaffected (store in $effect_str) 
    behavior_comparison[[bool_annotation_colname]] <- (behavior_comparison$reference_behavior_type != behavior_comparison$test_behavior_type)
    
    behavior_comparison <- behavior_comparison %>% 
                           mutate(effect_str = case_when(
                               .[[bool_annotation_colname]] == FALSE ~ "unaffected_",
                               .[[bool_annotation_colname]] == TRUE ~ "affected_")) 
    
    # Add affected/unaffected strings to simple & full behavior descriptors
    behavior_comparison[[simple_annotation_colname]] <- paste0(behavior_comparison$effect_str,
                                                               behavior_comparison[[simple_annotation_colname]])
    behavior_comparison[[full_annotation_colname]] <- paste0(behavior_comparison$effect_str,
                                                             behavior_comparison[[full_annotation_colname]])
    
    # Drop the extraneous columns used in processing, remerge with feature_metadata & return
    comparison_data <- behavior_comparison %>% select_("id",
                                                       simple_annotation_colname, 
                                                       full_annotation_colname,
                                                       bool_annotation_colname)
    feature_metadata <- dplyr::left_join(feature_metadata, comparison_data, by = "id")
    
    return(feature_metadata)
}







subsetCountMatrix <- function(countMatrix, peakNames) {
  # Input = countMatrix & names of features (rownames of countmatrix)
  # ouput: countMatrix only of features named in peakNames
  subset <- countMatrix %>% data.frame(.) %>% 
            tibble::rownames_to_column(., var = "peakID") %>% 
            filter(., peakID %in% peakNames) %>% 
            tibble::column_to_rownames(., var = "peakID")
                                  
  ifelse(nrow(subset) == length(peakNames),
         yes = return(subset),
         no = stop("subsetted matrix is not same length as peakNames")
         )
}


subsetOverlaps_and_flag_nonunique <- function(summits, peaks, dropMetadata = T){
  # This function will return summmits found within peaks, 
  # additionally, it will return the GRanges object with a column mcols()$unique
  # which describes whether a summit was the only summit found within the peak it overlapped.
  # The user can later decide how these summits should be handled.
  overlaps <- findOverlaps(summits, peaks)
  non_unique <- overlaps[!isUnique(subjectHits(overlaps))]
  
  ov_summits <- summits
  ov_peaks <- peaks[subjectHits(overlaps)]
  # drop extraneous metadata 
  # (ensures equal number of columns in GRanges & dropping redundant information)
  #mcols(ov_summits) <- ifelse(dropMetadata == T, NULL, mcols(ov_summits))
  mcols(ov_summits) <- NULL
  
  # Label whether peaks are unique overlaps or not,
  # this way the user can make a decision about how to handle them.
  mcols(ov_summits)$unique <- TRUE
  mcols(ov_summits[queryHits(non_unique)]) <- FALSE
  ov_summits <- ov_summits[queryHits(overlaps)]
  
  merged_metadata <- c(mcols(ov_summits), mcols(ov_peaks))
  # XXX 
  # return summit metadata to the overlap summits
  #message("WARNING: NEED TO DEBUG") 
  #return(ov_summits)
  if (dropMetadata == T){
    return(ov_summits)
  } else{
   mcols(ov_summits) <- merged_metadata
   return(ov_summits)
  }
}


